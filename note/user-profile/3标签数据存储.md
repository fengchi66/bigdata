## 数据架构

在 用户画像简介 中提到过一个通用的用户画像建设架构，也就是一个典型的Lambda架构。这里参考用户画像工程化解决方案，在整个工程化方案中，系统依赖的基础设施包括**Spark、Hive、HBase、Airflow、MySQL、Redis、Elasticsearch**。除去基础设施外，系统主体还包括 **Flink、ETL、产品端** 3个重要组成部分。图 2-1 所示是用户画像数仓架构图，下面对其进行详细介绍。  

![68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303131393030353731303936352e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c](https://gitee.com/joeyooa/data-images/raw/master/note/2021/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303131393030353731303936352e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c.png)

下方虚线框中为常见的**数据仓库ETL加工流程**，也就是将**每日的业务数据、日志数据、埋点数据等经过ETL过程，加工到数据仓库对应的ODS层、DW层、DM层中**。

​    中间的虚线框即为用户画像建模的主要环节，**用户画像不是产生数据的源头，而是对基于数据仓库ODS层、DW层、DM层中与用户相关数据的二次建模加工**。在ETL过程中将用户标签计算结果写入**Hive**，由于不同数据库有不同的应用场景，后续需要进一步将数据同步到`MySQL`、`HBase`、`Elasticsearch` 等数据库中。

- Hive：**存储用户标签计算结果**、**用户人群计算结果**、**用户特征库计算结果**
- MySQL：**存储标签元数据**，**监控相关数据**，**导出到业务系统的数据**
- HBase：**存储线上接口实时调用类数据**
- Elasticserch：**支持海量数据的实时查询分析**，**用于存储用户人群计算、用户群透视分析所需的用户标签数据**（由于用户人群计算、用户群透视分析的条件转化成的SQL语句多条件嵌套较为复杂，使用 Impala 执行也需花费大量时间）

​    **用户标签数据在Hive中加工完成后，部分标签通过Sqoop同步到MySQL数据库，提供用于BI报表展示的数据、多维透视分析数据、圈人服务数据；另一部分标签同步到HBase数据库用于产品的线上个性化推荐**     