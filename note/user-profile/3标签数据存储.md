## 数据架构

在 用户画像简介 中提到过一个通用的用户画像建设架构，也就是一个典型的Lambda架构。这里参考用户画像工程化解决方案，在整个工程化方案中，系统依赖的基础设施包括**Spark、Hive、HBase、Airflow、MySQL、Redis、Elasticsearch**。除去基础设施外，系统主体还包括 **Flink、ETL、产品端** 3个重要组成部分。图 2-1 所示是用户画像数仓架构图，下面对其进行详细介绍。  

![68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303131393030353731303936352e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c](https://gitee.com/joeyooa/data-images/raw/master/note/2021/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303131393030353731303936352e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c.png)

下方虚线框中为常见的**数据仓库ETL加工流程**，也就是将**每日的业务数据、日志数据、埋点数据等经过ETL过程，加工到数据仓库对应的ODS层、DW层、DM层中**。

​    中间的虚线框即为用户画像建模的主要环节，**用户画像不是产生数据的源头，而是对基于数据仓库ODS层、DW层、DM层中与用户相关数据的二次建模加工**。在ETL过程中将用户标签计算结果写入**Hive**，由于不同数据库有不同的应用场景，后续需要进一步将数据同步到`MySQL`、`HBase`、`Elasticsearch` 等数据库中。

- Hive：**存储用户标签计算结果**、**用户人群计算结果**、**用户特征库计算结果**
- MySQL：**存储标签元数据**，**监控相关数据**，**导出到业务系统的数据**
- HBase：**存储线上接口实时调用类数据**
- Elasticserch：**支持海量数据的实时查询分析**，**用于存储用户人群计算、用户群透视分析所需的用户标签数据**（由于用户人群计算、用户群透视分析的条件转化成的SQL语句多条件嵌套较为复杂，使用 Impala 执行也需花费大量时间）

​    **用户标签数据在Hive中加工完成后，部分标签通过Sqoop同步到MySQL数据库，提供用于BI报表展示的数据、多维透视分析数据、圈人服务数据；另一部分标签同步到HBase数据库用于产品的线上个性化推荐**     

## 标签数据存储之Hive

### 数据存储建模

站在数仓开发的角度来看，即是将数仓中建模好的数据，包括业务数据与用户埋点数据，基于一定的统计、规则、算法将数仓中的数据加工成用户标签树。数仓建模、分层的方法这里不做多的介绍，按照规范，用户画像的输入数据为Hive中DWD表，输出为DWS层。重点考虑标签表的设计。Hive存储标签相关的数据涉及到的一些表：

- 用户标签表
- 标签聚合的表
- 人群计算的表

#### 宽表

如果将用户标签开发成一张大的宽表，以Hive为例，我们最常用的就是宽表，也就是一个 key，跟上它的所有标签。比如下面是一个简单的宽表。

| 用户ID | 性别 | 年龄 | 学历 | 职业   | 月薪    | 月消费能力 |
| :----- | :--- | :--- | :--- | :----- | :------ | :--------- |
| 001    | 男   | 28   | 本科 | 程序员 | 10k-20k | 1k-2k      |
| 002    | 女   | 23   | 大专 | 销售   | 不详    | 100-200    |

那么用宽表有什么问题吗？

- 由于用户的标签会非常多，而且随着用户画像的深入，会有很多细分领域的标签，这就意味着标签的数量会随时增加，而且可能会很频繁。
- 不同的标签计算频率不同，比如说学历一周计算一次都是可以接收的，但是APP登录活跃情况却可能需要每天都要计算。
- 计算完成时间不同，如果是以宽表的形式存储，那么最终需要把各个小表的计算结果合并，此时如果出现了一部分结果早上3点计算完成，一部分要早上10点才能计算完成，那么宽表最终的生成时间就要很晚。
- 大量空缺的标签会导致存储稀疏，有一些标签会有很多的缺失，这在用户画像中很常见。

当标签数量较多的时候，我们必须考虑以上问题，且增加ETL任务的时间，维护困难。

#### 竖表

竖表即是将userId + 标签ID作为分组的key存储。竖表其实就是将标签都拆开，一个用户有多少标签，那么在这里面就会有几条数据。

| 用户ID | 标签名       | 标签值  |
| :----- | :----------- | :------ |
| 001    | sex          | 男      |
| 001    | salary_month | 10k-20k |
| 002    | sex          | 女      |
| 002    | age          | 23      |

竖表能比较好地解决上面宽表的问题。但是它也会带来了新的问题，比如说多标签组合的查询需求：“我们想看年龄在23-30之间，月薪在10-20k之间，喜欢听古典音乐的女性”，这种多标签查询条件组合情况在竖表中就不太容易支持。

#### 横表+竖表

如前面所分析，竖表和横表各有所长和所短，那么能不能两者结合呢？

这其实也要考虑横表和竖表的特性，整体来讲就是竖表对计算层支持的好，横表对查询层支持的好。那么设计的化就可以这样：

<img src="https://gitee.com/joeyooa/data-images/raw/master/note/2021/image-20210605155208457.png" alt="image-20210605155208457" style="zoom:50%;" />



#### 分区存储

如果将用户标签开发成一张大的宽表，在这张宽表下放几十种类型标签，那么每天该画像宽表的ETL作业将会花费很长时间，而且不便于向这张宽表中新增标签类型。

​    要解决这种ETL花费时间较长的问题，可以从以下几个方面着手：

- 将数据分区存储，分别执行作业；
- 标签脚本性能调优；
- 基于一些标签共同的数据来源开发中间表。

​    下面介绍一种用户标签分表、分区存储的解决方案。

​    根据标签指标体系的人口属性、行为属性、用户消费、风险控制、社交属性等维度分别建立对应的标签表进行分表存储对应的标签数据。如下图所示。

- 人口属性表：dw.userprofile_attritube_all；
- 行为属性表：dw.userprofile_action_all；
- 用户消费表：dw.userprofile_consume_all；
- 风险控制表：dw.userprofile_riskmanage_all；
- 社交属性表：dw.userprofile_social_all

![68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303232313039353131393637332e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c](https://gitee.com/joeyooa/data-images/raw/master/note/2021/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303232313039353131393637332e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c.png)

用户的人口属性宽表：

![68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303232313039353233323138312e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c](https://gitee.com/joeyooa/data-images/raw/master/note/2021/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303232313039353233323138312e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c.png)

- 其他id维度（如cookieid、deviceid、registerid等）的标签数据存储，也可以使用上面案例中的表结构。

​    在上面的创建中通过设立人口属性维度的宽表开发相关的用户标签，为了提高数据的插入和查询效率，在Hive中可以使用分区表的方式，将数据存储在不同的目录中。在Hive使用select查询时一般会扫描整个表中所有数据，将会花费很多时间扫描不是当前要查询的数据，为了扫描表中关心的一部分数据，在建表时引入了partition的概念。在查询时，可以通过Hive的分区机制来控制一次遍历的数据量。

​	所以Hive中的各个维度的用户标签相关的表结构采用竖表的设计：

```sql
CREATE TABLE IF NOT EXISTS dws_user_profile_attritube
(
    user_id STRING COMMENT '用户id',
    value   STRING COMMENT '标签权重'
) 
COMMENT '人口属性维度用户标签表'
PARTITIONED BY
(
    dt      STRING COMMENT '日期分区',
    tag_id  STRING COMMENT '标签id'
);
```

### 标签汇聚

在上面一节提到的案例中，用户的每个标签都插入到相应的分区下面，**但是对一个用户来说，打在他身上的全部标签存储在不同的分区下面。为了方便分析和查询，需要将用户身上的标签做聚合处理**。标签汇聚后将一个每个用户身上的全量标签汇聚到一个字段中，表结构设计如下：

```
CREATE TABLE `dw.userprofile_userlabel_map_all`
(
    `userid`     string COMMENT 'userid',
    `userlabels` map<string,string> COMMENT 'tagsmap',
)
    COMMENT 'userid 用户标签汇聚'
    PARTITIONED BY ( `data_date` string COMMENT '数据日期')
```

![68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303232313039353630333134312e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c](https://gitee.com/joeyooa/data-images/raw/master/note/2021/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303232313039353630333134312e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c.png)

- 开发udf函数“cast_to_json”将用户身上的标签汇聚成json字符串，执行命令将按分区存储的标签进行汇聚：

```
insert overwrite table dw.userprofile_userlabel_map_all partition(data_date= "data_date")  
  select userid,  
         cast_to_json(concat_ws(',',collect_set(concat(labelid,':',labelweight)))) as userlabels
      from “用户各维度的标签表” 
    where data_date= " data_date " 
group by userid
```

- 汇聚后用户标签的存储格式如图所示

  ![68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303232313039353733313536372e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c](https://gitee.com/joeyooa/data-images/raw/master/note/2021/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303232313039353733313536372e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c.png)

- 将用户身上的标签进行聚合便于查询和计算。例如，在画像产品中，输入用户id后通过直接查询该表，解析标签id和对应的标签权重后，即可在前端展示该用户的相关信息

### ID-MAPPING

开发用户标签的时候，有项非常重要的内容——**ID-MApping**，**即把用户不同来源的身份标识通过数据手段识别为同一个主体**。用户的属性、行为相关数据分散在不同的数据来源中，通过ID-MApping能够把用户在不同场景下的行为串联起来，消除数据孤岛。下图展示了用户与设备间的多对多关系。

![img](https://camo.githubusercontent.com/722c0b31c5d57bdf4d6d3987e48ea88edef2b19276dc39abca30c895737fb28d/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303232313130303031323438342e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c33646c61586870626c38304e444d784f44677a4d413d3d2c73697a655f31362c636f6c6f725f4646464646462c745f3730237069635f63656e746572)

-举例来说，用户在未登录App的状态下，在App站内访问、搜索相关内容时，记录的是设备id（即cookieid）相关的行为数据。而用户在登录App后，访问、收藏、下单等相关的行为记录的是账号id（即userid）相关行为数据。虽然是同一个用户，但其在登录和未登录设备时记录的行为数据之间是未打通的。通过ID-MApping打通userid和cookieid的对应关系，可以在用户登录、未登录设备时都能捕获其行为轨迹。

下面通过一个案例介绍如何通过Hive的ETL工作完成ID-Mapping的数据清洗工作。

**缓慢变化维是在维表设计中常见的一种方式，维度并不是不变的，随时间也会发生缓慢变化**。如用户的手机号、邮箱等信息可能会随用户的状态变化而改变，再如商品的价格也会随时间变化而调整上架的价格。因此在设计用户、商品等维表时会考虑用缓慢变化维来开发。同样，在设计ID-Mapping表时，由于一个用户可以在多个设备上登录，一个设备也能被多个用户登录，所以考虑用缓慢变化维表来记录这种不同时间点的状态变化（图3-9）。

![68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303232313130303230333138332e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c](https://gitee.com/joeyooa/data-images/raw/master/note/2021/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303231303232313130303230333138332e706e673f2c747970655f5a6d46755a33706f5a57356e6147567064476b2c736861646f775f31302c746578745f6148523063484d364c7939696247396e4c6d4e7a5a473475626d56304c.png)

拉链表是针对缓慢变化维表的一种设计方式，记录一个事物从开始到当前状态的全部状态变化信息。

在上图中，通过拉链表记录了userid每一次关联到不同cookieid的情况。如userid为44463729的用户，在20190101这天登录某设备，在6号那天变换了另一个设备登录。其中start_date表示该记录的开始日期，end_date表示该记录的结束日期，当end_date为99991231时，表示该条记录当前仍然有效。

​    首先需要从埋点表和访问日志表里面获取到cookieid和userid同时出现的访问记录。下面案例中，`ods.page_event_log`是埋点日志表，`ods.page_view_log`是访问日志表，将获取到的userid和cookieid信息插入cookieid-userid关系表（`ods.cookie_user_signin`）中。代码执行如下：

```sql
INSERT OVERWRITE TABLE ods.cookie_user_signin PARTITION (data_date = '${data_date}')
  SELECT t.*
    FROM (
         SELECT userid,
                cookieid,
                from_unixtime(eventtime,'yyyyMMdd') as signdate
           FROM ods.page_event_log      -- 埋点表
           WHERE data_date = '${data_date}'
        UNION ALL
         SELECT userid,
                cookieid,
                from_unixtime(viewtime,'yyyyMMdd') as signdate
           FROM ods.page_view_log   -- 访问日志表
           WHERE data_date = '${data_date}'
           ) t
```

​    创建ID-Map的拉链表，将每天新增到ods.cookie_user_signin表中的数据与拉链表历史数据做比较，如果有变化或新增数据则进行更新。

```
CREATE TABLE `dw.cookie_user_zippertable`(
`userid` string COMMENT '账号ID', 
`cookieid` string COMMENT '设备ID', 
`start_date` string COMMENT 'start_date', 
`end_date` string COMMENT 'end_date')
COMMENT 'id-map拉链表'
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
```

​    创建完成后，每天ETL调度将数据更新到ID-Mapping拉链表中，任务执行如下。

```sql
INSERT OVERWRITE TABLE dw.cookie_user_zippertable
SELECT t.* 
  FROM (
      SELECT t1.user_num,
             t1.mobile,
             t1.reg_date,
             t1.start_date,
             CASE WHEN t1.end_date = '99991231' AND t2.userid IS NOT NULL THEN '${data_date}'
                  ELSE t1.end_date
             END AS end_date
       FROM dw.cookie_user_zippertable t1
    LEFT JOIN (  SELECT *
                 FROM ods.cookie_user_signin
                WHERE data_date='${data_date}'
              )t2
           ON t1.userid = t2.userid
UNION
       SELECT userid,
              cookieid,
              '${data_date}' AS start_date,
              '99991231' AS end_date
        FROM ods.cookie_user_signin
       WHERE data_date = '${data_date
       }'
          ) t
```

​    数据写入表中，如上图所示。

​    对于该拉链表，可查看某日（如20190801）的快照数据。

```
select  * 
from dw.cookie_user_zippertable 
where start_date<='20190801' and end_date>='20190801'
```

​    例如，目前存在一个记录userid和cookieid关联关系的表，但是为**多对多**的记录（即一个userid对应多条cookieid记录，以及一条cookieid对应多条userid记录）。这里可以通过拉链表的日期来查看某个时间点userid对应的cookieid。查看某个用户（如32101029）在某天（如20190801）关联到的设备id

```sql
select cookieid 
from dw.cookie_user_zippertable 
where userid='32101029' and start_date<='20190801' and end_date>='20190801'
```

​    可看出用户‘32101029’在历史中曾登录过3个设备，通过限定时间段可找到特定时间下用户的登录设备。

​    在开发中需要注意关于userid与cookieid的多对多关联，如果不加条件限制就做关联，很可能引起数据膨胀问题：

​    在实际应用中，会遇到许多需要将userid和cookieid做关联的情况。例如，需要在userid维度开发出该用户近30日的购买次数、购买金额、登录时长、登录天数等标签。前两个标签可以很容易地从相应的业务数据表中根据算法加工出来，而登录时长、登录天数的数据存储在相关日志数据中，日志数据表记录的userid与cookieid为多对多关系。因此在结合业务需求开发标签时，要确定好标签口径定义。