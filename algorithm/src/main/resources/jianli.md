## 个人信息

- 邬凤池    男    27岁        长江大学
- 手机：18817420995    邮箱：itwufc@163.com  教育经历：2014-09 ~ 2018-06
- 技术博客：https://github.com/fengchi66/bigdata

## 技能清单

- **计算机基础** ：熟悉数据结构和算法
- **编程语言**：熟练掌握Java、Scala语言，熟悉Spring等框架开发数据服务
- **离线数仓**：熟悉Hive离线数仓数据模型与分层设计、ETL流程，熟悉SQL、Spark等开发数据需求
- **实时计算**：熟悉实时数仓/流批一体系统设计，熟练掌握 Flink 的原理及使用，熟悉基于Flink的API编程、状态管理等，并构建端对端精确一次处理的数据平台，完成多个系统实时数据报表、指标的开发
- **数据平台**：基于Flink构建实时数据平台，包括元数据管理、SQL开发、UDF管理、自定义Connector、监控报警等功能
- **消息中间件**：熟悉Kafka、Redis等中间件的原理及使用
- **OLAP**：熟悉Clickhouse、阿里云Hologres的原理及使用
- **云原生**：了解Docker容器技术与Kubernetes容器编排体系，基于容器环境部署大数据平台服务与任务监控；熟悉Kubernetes的声明式API编程

## 工作经历

**上海一条网络（2020-05 ~ 至今 ）**

- **职位**：实时大数据工程师
- **工作内容**：
  - 基于Kafka、Flink、HBase、Clickhouse等框架从0到1完成基础平台、实时数仓、实时数据平台建设，对接数据与业务产品，迭代完善企业数据指标、用户标签、实时数据分析等场景
  - 埋点方案迭代，规范埋点数据治理流程并建立全链路的流量数据质量监控
  - 负责用户画像项目，分解产品需求与目标，确认离线实时用户标签口径，设计并统一标签数据存储模型；完成数据开发与测试，应用于推荐系统与用户分群的场景，实现对不同生命周期、不同标签组合的用户精细化运营

**上海阅维信息（2018-07 ~ 2020-05 ）**

- **职位**：大数据开发工程师
- **工作内容**：
  - 互联网金融行业大数据，从渠道投放、产品、运营等维度以及AARRR模型等统一数据指标口径，构建数据指标体系；并基于Spark、HQL等完成数据指标的开发
  - 参与公司用户特征平台项目的规划以及存储方案的制定，并负责HBase表结构的和二级索引的设计；HBase集群的日常运维工作
  - 基于Dubbo、Spring等框架负责用户特征平台数据服务接口的开发

## 项目经历

### 电商实时数仓建设

2021-02 ~ 2022-01  上海一条  实时大数据工程师

- **项目描述** :
  - 在埋点方案迭代到统一埋点体系的过程中，存在多个埋点数据源且缺乏全流程的实时流量监控；在实时数据OLAP以及API方面，由于没有统一数据模型，存在指标不能复用且难以和离线对数据等问题。在此背景下，从0到1设计并优化实时数据采集、存储、计算，提升了实时数据的可用性，并在实时指标、实时标签、实时OLAP、实时API等场景为产品运营等提供数据支持。
- **技术架构** : Canal、LogAgent、Kafka、Flink、Redis、HBase、Postgres、ClickHouse
- **工作内容** :
  - 推进Flink集群在k8s云环境的部署，开发端对端Exactly Once的一站式Flink SQL开发平台，并建立集群和任务层面的监控平台，提升开发效率和任务稳定性
  - 负责埋点流量数据实时ETL、Join、动态分发，统一流量数据模型；建立埋点页面事件全流程的数据质量监控体系，并实现基于规则告警，有效解决事件少埋、埋错、埋点偏移等问题，提升流量的数据治理周期
  - 基于Lambda设计实时数据模型与分层，建设交易、流量、商品、供应商等主题域宽表，统一实时数据指标口径，基于Flink SQL开发各业务域和用户周期全流程的实时指标；使用Redis、Postgres存储指标数据，降低了在线服务延迟以及提高QPS
  - 对接数据产品，梳理交易与埋点数据的用户标签体系建立，开发实时标签，Hbase统一离线与实时标签存储，提升用户分群的效率
  - 接手DataService服务统一对外API数据服务，提供搜索、推荐场景下的榜单等数据服务，提升QPS以及慢SQL查询
  - 在OLAP场景下，提供多维明细实时宽表，支持下游订单即席查询、事件页面分析、用户行为等数据分析场景，并解决了原来数据孤岛的问题

### 用户标签系统

2020-05 ~ 2021-01  上海一条  大数据开发工程师

- **项目描述**:
  - 该项目是在原CRM用户运营系统的基础上，完善原有CRM标签元数据、标签类型，以及更加精细划分用户生命周期和圈人工具，主要分为两部分：基于时间维度和经营维度的用户标签、在用户标签中通过查询+筛选的方式定向人群。
- **技术架构**：Hive、Kafka、Flink SQL、Spark SQL、HBase
- **工作内容**：
  - 对接数据产品和运营，对不同子系统之间做深入的数据探查，与CRM、推荐等业务方确认用户标签口径；划分离线、实时标签的数据建模与存储，沉淀标签开发文档
  - 基于Spark SQL、Flink SQL等开发用户基础属性、交易、用户行为、用户关系等维度的数据任务
  - 开发标签监控、人群计算监控、数据服务层监控等相关脚本
  - 负责开发用户标签数据接口，与push、推荐、广告系统的打通
  - 推动用户标签数据在产品、业务之间的使用情况，并定期反馈标签对人群交易、推荐效果的提升，优化标签规则形成闭环

### 数据指标体系建设
2019-07 ~ 2020-02  上海阅维  大数据开发工程师
- **项目描述**:
  - 该项目是服务于某线上金融公司的的一个数据产品项目，由于公司缺乏完善的数据建模且存在多个数据源、多套数据ETL逻辑的情况下，造成数据指标口径不一致；该项目主要针对信贷全流程-运营领域的指标进行建设：APP启动、注册、实名认证、提交授信申请、放款申请、放款成功、回访等全流程，拆解数据指标，确认指标口径，开发数据指标平台。
- **技术架构**：Flume、Sqoop、Kafka、Hive、Spark、Mysql
- **工作内容**：
  - 在Hive数仓ODS层数据的基础上，针对信贷全流程-运营领域的各级指标，进行数据探查，从功能渗透、功能转化、功能留存、关键维度等对指标进行拆解
  - 针对拆解指标，结合数据应用需求，在DWD、DWS完成核心指标的数据建模与ETL开发工作，将指标结果数据输出到Mysql
  - 建立数据指标监控体系，对各级关键指标，从同比、环比以及设备、APP版本、功能使用条件等维度，开发数据稽查脚本，当指标异常达到阈值能自动报警给开发相关人员
  - 完成数据测试后，编写上线文档、性能分析和总结文档
  - 后期对脚本进行维护和按照需求进行优化

### 用户特征平台
2018-08 ~ 2019-06  上海阅维  大数据开发工程师
- **项目描述**:
  - 对话单、传文件、群、朋友圈等微信行为数据，基于Hive搭建分层次的离线数仓，Spark计算后对各维度数据使用Hbase及ES业务展示；后期基于设计Flink开发实时数仓，对微信用户特征提供实时大屏。
- **技术架构**：Kafka、Spark、HBase、ES、Flink
- **工作内容**：
  - 使用Spark Core完成数仓各层次数据的计算，如对数据打标签、解析业务指标、离线实现主对端建联
  - 采用Hbase+ES的二级索引实现，负责微信模块展示Hbase表的设计、根据数据特点 以及集群资源实现RowKey设计与预分区的设计；并使用Hbase实现每日TB级图片数据的存储
  - 基于实时场景的迫切需求，使用Kafka -> Flink -> Hbase 的架构实现实时数仓，负责实时部分流量域宽表、用户标签的开发
  - Kafka->Flink->Hbase端对端Exactly Once的实现；并开发自定义Metrics埋点，reporter上报到influxDB，结合Grafana搭建对线上任务、实时作业的内存、GC、吞吐、反压、延迟的监控平台。


## 个人评价

4年大数据开发经验，其中2年实时开发，熟悉数仓数据建模与开发，独立设计并开发电商领域的实时数仓、实时数据平台；偏底层数据开发与平台开发，对Kafka、Flink等开源框架有较深入研究