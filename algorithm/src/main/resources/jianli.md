## 个人信息

- 邬凤池/男/27岁/湖北
- 手机：18817420995，邮箱：itwufc@163.com
- 技术博客：https://gitee.com/joeyooa/bigdata

## 求职意向

- 期望职位：大数据开发/数据平台开发
- 期望城市：上海

## 教育经历

| 学校     | 学历，专业         | 时间              |
| -------- | ------------------ | ----------------- |
| 长江大学 | 学士，资源勘查工程 | 2014.09 - 2018.06 |


## 技能清单

- **计算机基础** ：熟悉数据结构和算法
- **编程语言**：熟练掌握Java、Scala语言，熟悉Spring等框架开发后端应用
- **云原生**：熟悉Docker容器技术与Kubernetes容器编排体系，基于容器环境部署Flink、Spark等大数据框架、大数据平台服务与任务监控；熟悉Kubernetes的声明式API编程
- **离线数仓**：熟悉Hive离线数仓分层设计，熟悉SQL、Spark等开发数据需求
- **实时计算**：熟悉实时数仓/流批一体系统设计，熟练掌握 Flink 的原理及使用，熟悉基于Flink的API编程、状态管理等，并构建端对端精确一次处理的数据平台，有Flink线上调优经验
- **数据平台**：基于Flink构建实时数据平台，包括元数据管理、SQL开发、UDF管理、自定义Connector、监控报警等功能。
- **消息中间件**：熟悉Kafka、Redis等中间件的原理及使用
- **OLAP**：熟悉阿里云Hologres、Clickhouse的原理及使用

## 工作经历

**上海阅维信息（2019 年 1 月 ~ 2020 年 5 月 ）**

- **职位**：大数据开发工程师
- **工作内容**：电信行业大数据，基于Kafka、Spark、HBase、ES等大数据组件，用户特征系统、DMP平台的数据开发。

**上海一条网络（2020 年 5 月 ~ 至今 ）**

- **职位**：实时大数据开发
- **工作内容**：Kafka、Flink、HBase、Hudi等基础架构建设、数据开发，负责实时数仓、实时计算平台落地

## 项目经历 

### 实时数仓

2020-05~2021-2  一条  实时大数据开发

- **项目描述** : 
  - 一条作为自媒体与电商平台，对接电商平台的埋点流量数据与业务表数据，使用Canal、LogAgent等工具采集数据到Kafka，并做数据的分发、ETL等工作
  - 负责实时数仓系统设计：包括数据ETL、数仓分层、实时计算、数据应用等，支持实时数据看板、实时OLAP、实时标签、实时数据API等应用场景
  - 在用户关键行为模型计算的场景，负责Hudi数据湖的落地
- **工作内容** :
  - 推动Flink集群在Kubernetes云原生环境的部署，基于Prometheus、Grafana搭建线上Flink容器、Flink任务监控平台
  - 开发Flink程序对spm、神策埋点数据的ETL与迭代，客户端、服务端日志的分流、Join语义实现；实现动态规则的流量分发；Canal对业务数据的接入工作等
  - 负责基于Kafka、PostgreSQL的实时数仓ODS、DWD、DWS、ADS等分层设计，基于HBase/Redis设计DIM层，解决原来的烟囱式开发模式
  - 交易、流量、社区等不同数据域的宽表开发与数据指标开发，给搜索、广告、业务方等提供Dubbo服务
  - 基于线上模型训练场景，调研Hudi数据湖工具的落地，提供统一格式的用户关键行为表，解决Lambda架构下需要同时维护两套代码的痛点
  - 负责Clickhouse、阿里云Hologres的实时OLAP平台，支持订单即席查询、事件分析、用户路径、漏斗、Session等数据分析场景

### 实时数据平台

2021-04~2021-8  一条  实时大数据开发

- 项目描述：面对日益增长的实时数据开发与Flink SQL开发增长，传统的基于一个通用jar包与配置中心提交任务的方式已不合适，且元元数据、UDF、SQL开发、数据地图、监控等都没有得到有效的管理；基于以上问题，调研业界实时平台的构建经验，开发实时数据平台。
- 工作内容：
  - 基于官方Flink镜像，自定义JobManager、TaskManager镜像，封装统一的Deployment yaml文件，支持Flink任务以jar、SQL的方式提交到Session模式与Application模式的集群
  - 使用Flink Sql Gateway服务，管理Flink SQL中的元数据与UDF，并通过SQL-CLI提交SQL任务。
  - 平台集成Savepoint等任务状态管理，实现端对端的精确一次消费与任务恢复
  - 在官方开源Connector的基础上，自定义Redis、ClickHouse的Connector，丰富异构数据源的集成
  - 支持一条线上 20+ Flink Jar任务和80+ Flink SQL任务的开发任务，支持业务方、产品等数据需求

## 个人评价

待人真诚，能够与团队融洽相处，有较强的团队合作意识；对工作认真负责，有较强的责任心。极客精神，注重不断学习新的技术，勤于思考，自我完善。

<div style="page-break-after: always;"></div>